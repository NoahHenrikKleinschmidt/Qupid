{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <img src=\"./.resources/tiny.svg\" width=\"31\"> Qupid\n",
    "\n",
    "##  <font style=\"color:rgb(255, 82, 88)\">Qu</font>antitative <font style=\"color:rgb(255, 82, 88)\">P</font>CR <font style=\"color:rgb(255, 82, 88)\">I</font>nterface to <font style=\"color:rgb(255, 82, 88)\">D</font>elta-Delta-Ct\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this tutorial we shall briefly introduce the interface of `Qupid`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Layout\n",
    "----------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Qupid offers essentially a three-section layout, with an upper part for `File Upload`, a middle part for `Delta-Delta-Ct Analysis` setup, and a lower part to inspect the `Results`. \n",
    "Each section will only appear after working on the section above is done."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](./.resources/upload_files.png)\n",
    "![](./.resources/analyse_1.png)\n",
    "![](./.resources/results_1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Uploading Data\n",
    "----------------------------------------------------------------\n",
    "\n",
    "Qupid supports all datafile types supported by the <a href = \"https://github.com/NoahHenrikKleinschmidt/qpcr.git\">qpcr python module</a> with the exception of \"irregular\" single-assay datafiles. Check out the [Getting Started Tutorial](https://github.com/NoahHenrikKleinschmidt/qpcr/blob/main/Examples/0_getting_started.ipynb) of the `qpcr` module to learn about the accepted types of input datafiles."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Qupid offers three separate methods to upload its accepted data inputs. We shall go over each one individually. You can specify an input method, provide details on how to read your file, and subsequently hit the `Read my File(s)` button."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Uploading single-assay datafiles\n",
    "\n",
    "If you have your assays (or just generally your \"datasets\") stored already in separate files, then you can simply upload a number of files for your \"assays-of-interest\" (henceforth just called \"assays\") and then some others for your \"normaliser assays\" (henceforth just called \"normalisers\"). \n",
    "\n",
    "You can choose this type of Data Input by clicking on the first button to the left labeled `Upload multiple Files`. \n",
    "\n",
    "> In this case your files **must** all be identically structured! That means, same filetype (csv or excel) and same numbers of columns etc. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](./.resources/single_assay_1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the input form has rendered, you can drag&drop your desired files into the two provided upload windows. We will next discuss the various elements that you may encounter when uploading your files here. Note that most of these will also appear in the other types of inputs!\n",
    "\n",
    "#### Infer Replicates\n",
    "If your replicates are identically labelled (i.e. `ctrl, ctrl, ctrl` and not `ctrl1, ctrl2, ctrl3`) then Qupid will be able to interpret your data organisation automatically. However, if this is not possible, or you wish to use a specific arrangement, you can manually specify replicate information. Simply uncheck the `Infer replicates` box and new inputs will appear asking you to provide the number of entries in each _replicate group_ (likely your different qPCR samples).If the terms `replicates` and `groups` are alien to you, check out [this paragraph](https://noahhenrikkleinschmidt.github.io/qpcr/index.html#replicates) from the `qpcr` documentation that should make things clear.\n",
    "\n",
    "> When manually specifying replicate groups, you can also specify arbitrary text-labels to your groups. Note, that when manually specifying the replicate information then really **all** assays have to have identical entries (if one has a diluent sample but the other does not, then this will be unreadable!). Qupid is more forgiving for `inferred` replicates, but unequal groups will lead to data-loss downstream! If you know the replicate groups that are uncommon are not important to you (like the diluent) you can go ahead with your analysis, but this is not advised. It is considered better to introduce dummy entries (with `NaN` Ct values for instance) for any group that is not shared among all assays."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](./.resources/replicates_infer.png)\n",
    "\n",
    "<br>\n",
    "\n",
    "![](./.resources/replicates.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Columns\n",
    "Qupid is interested in two data columns: one for replicate identifiers and one for Ct values. If your file contains **exactly** two columns, then these will be interpreted as `id` (1st!) and `Ct` (2nd!) directly. However, if your file contains more than two columns Qupid will ask you to provide the column names where your ids and Ct values are stored. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](./.resources/data_cols.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Csv Delimiter\n",
    "\n",
    "Some `csv` files use a semicolon `;` instead of a comma `,` do separate cells from each other. \n",
    "If you upload a `csv` file Qupid will ask you to specify which delmiter your file uses.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](./.resources/csv_delim.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Uplading a single multi-assay datafile\n",
    "The second option is pretty diverse. You can upload one single datafile that contains mulitple datasets you wish to include in your analysis. This \"multi-assay\" datafile can either be a `csv` file, a single-sheet `excel` , or multi-sheet `excel` file. In order for this input to be readable the assays **need to be decorated**. Check out the [Decorator Tutorial](https://github.com/NoahHenrikKleinschmidt/qpcr/blob/main/Examples/8_decorating_datafiles.ipynb) to learn how to add decorators to your multi-assay datafiles.\n",
    "\n",
    "You can select this type of data input by clicking on the second button to the left, and the drag&drop your desired datafile into the upload field that pops up. Notice how the `Infer replicates` checkbox from before is also present again? Also note that for multi-assay files it is assumed that there are multiple data-columns, so an input for column headers storing replicate identifiers and Ct values is required!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](./.resources/multi_assay_1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transposed files\n",
    "\n",
    "By default separate assay tables are below one another and separated by blank lines. However, it is also possible to read datafiles where separate assays are next to one another. In this case, hit the `Read transposed` checkbox. If you checked out the [Decorator Tutorial](https://github.com/NoahHenrikKleinschmidt/qpcr/blob/main/Examples/8_decorating_datafiles.ipynb) you will have seen an example of _transposed_ datafile."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](./.resources/transposed.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Assay patterns and the Assay column\n",
    "These two are important! When you look at your datafiles, the cell content of your \"assay header\" may not only contain the actual name of the assay but other things as well. For instance, Qiagen's Rotor-Gene produces files that store the assay headers as \"Quantitative analysis of A.{color} ({assay})\". \n",
    "Now, the analysis would work just as well by taking all of this as assay name (this is the default settings \"all\" ), but it's usually much nicer to remove the unnecessary parts. To that end, Qupid offers `pattern extraction` using `regex`. The Rotor-Gene pattern is already pre-installed. If you have a different pattern in your files, please, post an [issue on github](https://github.com/NoahHenrikKleinschmidt/qpcr-Analyser/issues) about it and provide some examples. Note, however, that the assay pattern input is not strictly required.\n",
    "\n",
    "The `assay column`, however, **is** required. This is the data column in which your assay headers appear. They all have to be in the same column, usually the first column (this is the default settings). Note, the input for assay \"column\" will be interpreted as \"row\" for _transposed_ files. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](./.resources/assay_pattern.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data-Sheet input\n",
    "If your file contains multiple datasheets, you will be asked if you would like to read **all** of them, or only a single one. You can choose a specific sheet by unchecking the `Read all sheets from my file` box and then choose a sheet from the drop-down menu."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](./.resources/multi_sheet1.png)\n",
    "\n",
    "<br>\n",
    "\n",
    "![](./.resources/multi_sheet2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Uploading \"Big Table\" files\n",
    "A \"Big Table\" datafile stores all its data in one single datatable. There are three different types of \"Big Tables\" that are supported by Qupid: `horizontal`, `vertical`, and `hybrid`. If you checked out the [Decorator Tutorial](https://github.com/NoahHenrikKleinschmidt/qpcr/blob/main/Examples/8_decorating_datafiles.ipynb) you will have seen examples of all three of them and how they have to be decorated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](./.resources/bigtable_1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Kind of Big Table\n",
    "Qupid will ask you which kind of Big Table is present in your datafile. After choosing from the three options, you will observe that the inputs below are adjusted. You have seen the kinds of inputs already, so there's nothing new here. In case you are unclear about something, consult the hoverinfo-help that each widget provides."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](./.resources/bigtable_kind.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reading your data\n",
    "Once the setup is finished, you have to hit the `Read my File(s)` button in order to actually import your data.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](./.resources/readbutton.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point you will either receive a green success message or a red error message.\n",
    "The errors try to be as informative as possible without being too technical, but that's not always possible. Make sure to properly provide appropriate specifics for file reading, and you should be fine. Also make sure to also consider less obvious error sources like the wrong csv delimiter or the wrong assay column. \n",
    "\n",
    "> A Note on \"damaged\" excel files. If you have an `excel` file that produces some \"damaged\" massage when opening it, but excel says it was able to recover or repair the file, it is likely that the file will be unreadable by Qupid! Best copy the data you are interested in to a new file and check if that one is now undamaged. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](./.resources/sucess.png)\n",
    "\n",
    "<br>\n",
    "\n",
    "![](./.resources/fail.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Analysis Setup\n",
    "----------------------------------------------------------------\n",
    "Now that the files are properly imported, we can start setting up our actual `Delta-Delta-Ct` analysis. \n",
    "\n",
    "First, you may select some basic setup, such as which kind of filtering to apply to your data before analysis. These are the controls on the left. Then, on the right you can adjust the actual settings of your main computation. Here a number parameters may be set, and we will next look at these."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](./.resources/analyse_1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Calibrating Assays\n",
    "\n",
    "Qupid allows to either load externally computed qPCR primer efficiencies or to compute new efficiencies directly from loaded assays. To include efficiency data, select the `Calibrate assays` checkbox. Thereafter a number of new settings will appear for calibration. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](./.resources/calibrate_1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reference Efficiency Files\n",
    "\n",
    "If you have externally computed efficiencies you may upload them as a default comma-separated `csv` file with two named columns, one for the assay ids and one for the efficiencies. Note, Qupid will only be able to assign efficiencies based on matching ids, so make sure your assay ids have a corresponding partner in your reference file. If none can be found, the default 100% efficiency is retained. \n",
    "\n",
    "> Note: <br> This step is fully optional, if you have a set of calibrator replicates from a dilution series, Qupid can directly compute the efficiency based on your supplied data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compute new effiencies \n",
    "If your assays contain \"calibrator\" replicates that come from a dilution series, Qupid is able to directly compute the qPCR primer efficiency from these. For this to work, Qupid requires that the corresponding replicates are decorated accordingly. Essentially, the required naming scheme is `calibrator : some_name : dilution`, where `dilution` is an optional parameter that specifies the inverse dilution step (e.g. `2`for a `1/2` dilution, or `16` for a `1/16` step etc.). Check out [the tutorial for the qpcr Calibrator](https://github.com/NoahHenrikKleinschmidt/Qupid/blob/main/9_custom_efficiencies.ipynb) for more information on replicate decoration."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Removing Calibrator replicates\n",
    "By default Qupid assumes that you have calibrator replicates and replicates-of-interest for Delta-Delta-Ct analysis together in the same assay. Hence, Qupid will remove any `calibrator: ...` decorated replicates from your assays after computing or assigning an efficiency. If you wish to retain these replicates, simply uncheck the `Remove calibrator replicates` checkbox. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dilution step\n",
    "\n",
    "Qupid requires some information about the dilution in order to perform linear regression and thus compute an efficiency. If you specified dilution steps in your replicate names by the scheme outlined above, then Qupid will be automatically able to read them. However, if you did not specify dilution steps in your replicate identifiers you will have to manually specify the dilution step(s). To do so, simply uncheck the `Infer dilution step` checkbox and enter a number for your inverse dilution step (e.g. `2` if you always performed `1/2` steps).\n",
    "\n",
    "> Note: <br> If there are gaps in your dilution steps, you will need to specify the dilution step directly in the replicate identifiers as outlined above!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](.resources/calibrate_2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Filters\n",
    "Qupid offers two types of filters to vet your input Ct values. Either a _static_ `range filter` which will remove Ct values that lie outside a given range around the median of each replicate group (each qPCR sample), or a dynamic `IQR filter` that does the same but uses the interquartile-range instead a static range. Of course, you can disable filtering as well. Note, filtering may not make much sense for duplicate data, as the range filter may remove groups entirely if the two Ct values are too far apart, while an IQR filter would be unable to remove anything. But there is a significant speed-up by skipping filtering!\n",
    "\n",
    "#### Inclusion Range\n",
    "When choosing a filter you will be able to set a filtering `inclusion range` in the `Settings` column to the right. Any Ct value of any group that does not fall within the range parameters set, will be removed from analysis. Any Ct value of any group from any assay that is outside this inclusion range will be removed from analysis. The anchor of the inclusion range is always the _median_  value of the respective group."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](./.resources/filter_2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Anchor Settings\n",
    "Located at the top of the Settings column is an input for the `anchor`. The `anchor` is simply the assay-internal reference value which is used during `Delta-Ct` computation. By default Qupid will use simply the very first Ct value in your dataset, assuming that your first group is also your reference. However, other options exist. You may probably want to check out the `mean` anchor option, which allows you to reference against the mean of one specific group within your assays. You can check out the different anchor options and which additional inputs appear for each (it's quite intuitive). You can learn more about the anchors [in the qpcr documentation](https://noahhenrikkleinschmidt.github.io/qpcr/index.html#qpcr.Analyser.anchor)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](./.resources/anchor1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Normalisation Mode\n",
    "Qupid offers three methods to perform normalisation against your normaliser assays. By default it will choose `\"pair-wise\"` normalisation which will strictly normalise first replicates against first replicates, second against second, and so forth. This is the go-to method for multiplex experiments. However, if your replicates are not linked in a way because they were pipetted individually anyway, you may not wish to restrict your normalisation to this setup. Hence, two other options exist. `\"combinatoric\"` normalisation will, as the name implies, compute a normalisation for all possible combinations of first against first, against second, and so forth within a group. This method is markedly slower than pair-wise normalisation but very feasible for small size groups (like duplicates). On the other hand, if your groups are larger you may wish to avoid this tedious computation but still account for the equivalence of your samples. Therefore, Qupid offers the `\"permutative\"` method that will scramble the normaliser replicates randomly and then perform pair-wise normalisation. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](./.resources/normalisation_mode.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5 Running your analysis\n",
    "Once you are happy with your setup you can start the computation. To do so, simply hit the `Run Analysis` in the `Basic Setup` column to the left."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](./.resources/run_button.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.6 Inspecting Results\n",
    "\n",
    "Once Qupid has finished the main computation, it will start presenting the results. If you selected so, then a replicate boxplot will be the first to appear in a (closed) expander to the right. Next, a box-plot summary of your filtering will appear if you selected filtering. Thereafter, an expander for any calibration regression lines will be shown, provided that you calibrated your assays and that any new efficiencies were actually computed. \n",
    "\n",
    "Then, you will see an open expander with your preview figure. Right underneath that one is another closed expander where you can inspect the summary table of your results. Finally, you will see some buttons appearing offering different download types for your results. \n",
    "\n",
    "The options to view your results are pretty intuitive, so we will not go into more detail on how they work. Simply explore and you will soon get the hang of it all!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](./.resources/results_1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Styling your Preview\n",
    "----------------------------------------------------------------\n",
    "\n",
    "If figure in the expander looks not quite to your liking, we can adjust a great number of parameters of the plotting in the Settings column. However, this requires a tiny bit (like 0.000001%) of knowledge of coding and which types of arguments are accepted. You can learn more about the possible arguments to customise your figures [in the qpcr documentation](https://noahhenrikkleinschmidt.github.io/qpcr/Plotters/Plotters.html). \n",
    "\n",
    "If you have an `interactive` figure then you can also adjust sizing, and axis scales etc. dynamically using the hovertools offered by `plotly` (the software used to produce the figures). Go check out how you can customise the figure to your delight. The settings are pretty simple. Note, `static` figure are only customisable through the `Plotting parameters` field in the Advanced Settings. It is suggested that you stick with the interactive figures, they more fun anyway. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Keeping records\n",
    "----------------------------------------------------------------\n",
    "One final item for this overview. In order to keep a record of what we did to perform our analysis, Qupid stores all its settings in a `Session Log`. You will find at the bottom of your results download buttons one labeled `Download Session Log`. You should really do this because it will tell you how to repeat your computations. It a simple `json` file that can be opened from any text editor. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With that we have reached the end of this tutorial. Hopefully, you now feel ready to use Qupid for your own analyses. Good Luck with your research! 🍀"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
